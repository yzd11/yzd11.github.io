<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="referrer" content="no-referrer"><title>强化学习 - yzd&#039;s Log Book</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="yzd&#039;s Log Book"><meta name="msapplication-TileImage" content="https://s2.loli.net/2024/11/11/wIobSZOAEGchgVv.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="yzd&#039;s Log Book"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="了解简单的强化学习"><meta property="og:type" content="blog"><meta property="og:title" content="强化学习"><meta property="og:url" content="https://yzd11.github.io/2024/09/18/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"><meta property="og:site_name" content="yzd&#039;s Log Book"><meta property="og:description" content="了解简单的强化学习"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726128985868-783ba096-524f-46ca-86e2-8d323f2d093d.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726130376079-0eea49f5-0366-4fd7-b7af-686a09a69449.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726131338806-0bfd8ada-e15c-4ace-a726-bd701cb119ed.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726131649478-02572d0a-a510-4612-8251-bf347a232c70.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726145604442-dcfbef47-8a1d-4521-b65d-ff3f62166f1b.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726146024569-16db0a74-cde0-4acb-8f60-8ca9df448c92.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726236383612-d803bbb4-c840-4ddf-8c93-7357f06da0a3.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726236581187-25cea284-f4f7-48d0-be8a-b5cc1c723385.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726649653666-1d559a7e-3237-4b67-adb9-60843bebbdf3.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726650010452-f655730d-7687-4781-bc16-f2226e2b601f.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726651251286-7f2cc463-ebda-4007-bbc9-47141c6c52fe.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726655233437-6b032134-96d7-4f52-a6c1-bc6cbbec3ded.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726655717999-956d66b9-266b-435a-9d36-5f30ab727937.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726656032263-9db4bf2f-2158-4fc5-932a-4c836c32a109.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726656450338-bd1e49c0-2408-4878-ad7b-2e0ecc72156d.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726656683775-51684b5c-19b6-40fa-b78a-98f81f829809.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726150873590-787a3380-d63b-4f5c-aec2-07e0026fe8ff.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726204536895-3c8db483-9bc1-470d-80a9-c042e64e309f.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726223602333-e74a970c-196f-4369-bea2-33f0f3c5f980.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726225565356-8535e491-af85-4123-a481-340f1c957316.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726227238694-a3ea5ec0-60eb-4912-ad22-a02ce3480e0b.png"><meta property="article:published_time" content="2024-09-18T10:55:36.000Z"><meta property="article:modified_time" content="2024-11-19T09:33:32.597Z"><meta property="article:author" content="yzd"><meta property="article:tag" content="Reinforcement learning"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726128985868-783ba096-524f-46ca-86e2-8d323f2d093d.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://yzd11.github.io/2024/09/18/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},"headline":"强化学习","image":["https://cdn.nlark.com/yuque/0/2024/png/40370285/1726128985868-783ba096-524f-46ca-86e2-8d323f2d093d.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726130376079-0eea49f5-0366-4fd7-b7af-686a09a69449.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726131338806-0bfd8ada-e15c-4ace-a726-bd701cb119ed.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726131649478-02572d0a-a510-4612-8251-bf347a232c70.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726145604442-dcfbef47-8a1d-4521-b65d-ff3f62166f1b.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726146024569-16db0a74-cde0-4acb-8f60-8ca9df448c92.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726236383612-d803bbb4-c840-4ddf-8c93-7357f06da0a3.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726236581187-25cea284-f4f7-48d0-be8a-b5cc1c723385.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726649653666-1d559a7e-3237-4b67-adb9-60843bebbdf3.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726650010452-f655730d-7687-4781-bc16-f2226e2b601f.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726651251286-7f2cc463-ebda-4007-bbc9-47141c6c52fe.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726655233437-6b032134-96d7-4f52-a6c1-bc6cbbec3ded.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726655717999-956d66b9-266b-435a-9d36-5f30ab727937.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726656032263-9db4bf2f-2158-4fc5-932a-4c836c32a109.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726656450338-bd1e49c0-2408-4878-ad7b-2e0ecc72156d.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726656683775-51684b5c-19b6-40fa-b78a-98f81f829809.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726150873590-787a3380-d63b-4f5c-aec2-07e0026fe8ff.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726204536895-3c8db483-9bc1-470d-80a9-c042e64e309f.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726223602333-e74a970c-196f-4369-bea2-33f0f3c5f980.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726225565356-8535e491-af85-4123-a481-340f1c957316.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1726227238694-a3ea5ec0-60eb-4912-ad22-a02ce3480e0b.png"],"datePublished":"2024-09-18T10:55:36.000Z","dateModified":"2024-11-19T09:33:32.597Z","author":{"@type":"Person","name":"yzd"},"publisher":{"@type":"Organization","name":"yzd's Log Book","logo":{"@type":"ImageObject","url":"https://s2.loli.net/2024/11/11/wIobSZOAEGchgVv.png"}},"description":"了解简单的强化学习"}</script><link rel="canonical" href="https://yzd11.github.io/2024/09/18/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"><link rel="icon" href="https://s2.loli.net/2024/11/11/wIobSZOAEGchgVv.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://s2.loli.net/2024/11/11/wIobSZOAEGchgVv.png" alt="yzd&#039;s Log Book" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">YZD&#039;S LOG BOOK</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/yzd11/"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-09-18T10:55:36.000Z" title="2024/9/18 18:55:36">2024-09-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-19T09:33:32.597Z" title="2024/11/19 17:33:32">2024-11-19</time></span><span class="level-item"><a class="link-muted" href="/categories/blog/">blog</a></span><span class="level-item">14 minutes read (About 2050 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">强化学习</h1><div class="content"><h2 id="xu0Pq">引入</h2>



<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726128985868-783ba096-524f-46ca-86e2-8d323f2d093d.png"></p>
<p>在强化学习中，不同于之前的监督学习，例如对于一个直升飞机来讲，似乎我们很难人为的评断什么是好的，什么是坏的，我们更多的是通过奖励来对其行为进行调整。</p>
<p>和监督学习相比较，强化学习中的标签是后给出的，与无监督学习相比，强化学习中使用了标签。</p>
<p>例如对于这个火星探测车，我们需要它拍摄到有价值的图片,也就是到达$ state1 $或$ state6 $，这样就可以得到奖励为$ 100 $或$ 40 $，假设我们现在处于$ 4 $这个状态，我们可以选择向左或者向右移动，最终到达奖励的位置。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726130376079-0eea49f5-0366-4fd7-b7af-686a09a69449.png"></p>
<p>刚才我们仅仅看到目的地的奖励，但是显然$ 100 $的距离却比$ 40 $要远，那么我们就需要把距离这个因素也计算进去。  因此我们引入了一个新的概念–<font style="background-color:#FBDE28;">折扣因子</font>$ \gamma $，在这里我们采用$ \gamma&#x3D;0.5 $的情况来进行评估。</p>
<p>$ Reward $<font style="background-color:#FBDE28;">奖励</font>，表示每个时刻采取动作后得到的是即时奖励</p>
<p>$ Return $<font style="background-color:#FBDE28;">回报</font>，表示在时刻采取某个动作后到游戏结束可以得到的总的奖励，即$ U_t&#x3D;R_t+R_{t+1}+R_{t+2}\ldots $</p>
<blockquote>
<p>“ 注意上面的$ U_t $公式中的$ reward $采用的是大写字母，因为它们表示的是随机变量，小写字母$ r_t $表示的是在时刻$ s_t $采取某个具体动作$ a_t $后得到的具体的奖励值。”</p>
</blockquote>
<p>上面给的$ U_t $计算公式是从$ t $时刻开始未来每个时刻的奖励的累加，可以看到所有时刻的$ reward $都是相同权重的。但是这样设计有一个问题，就是假如我现在给你$ 100 $和$ 1 $年后才给你$ 100 $，这两个$ 100 $显然不应该赋予相同权重，所以你经常可以看到$ return $计算时会有一个参数$ \gamma $,得到的是$ discounted \quad return $，即$ U_t&#x3D;R_t+\gamma R_{t+1}+\gamma^2R_{t+2}\ldots $</p>
<h2 id="kl2xD">策略</h2>


<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726131338806-0bfd8ada-e15c-4ace-a726-bd701cb119ed.png"></p>
<p>我们再介绍一个新的术语–<font style="background-color:#FBDE28;">策略</font>$ \pi $，我们使用$ \pi{(s)}&#x3D;a $表示在状态$ s $下采用决策$ a $，也就是表明了我们在状态$ s $下应该采用的决策。</p>
<h2 id="xkWyp">马尔科夫决策过程</h2>


<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726131649478-02572d0a-a510-4612-8251-bf347a232c70.png"></p>
<p>对用这种问题我们有一个经常使用的方法，称为<font style="background-color:#FBDE28;">马尔科夫决策过程</font>，我们对于一个状态采取一个决策，然后基于这些决策发生的变化，得到新的状态和奖励。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726145604442-dcfbef47-8a1d-4521-b65d-ff3f62166f1b.png"></p>
<p>我们再引入一个新的概念-<font style="background-color:#FBDE28;">动作价值函数</font>，$ Q(s,a) $表示等于回报值，如果在状态$ s $下采用一次决策$ a $，然后接下来进行最优选择。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726146024569-16db0a74-cde0-4acb-8f60-8ca9df448c92.png"></p>
<p>可以看到，最理想的收获值就是$ \max_{a}Q(s,a) $，在状态$ s $下最理想的决策就是可以使得$ Q $为最大值的决策。有的情况下这个函数也被写成$ Q^{*} $，实际上是一样的。</p>
<h2 id="apBak">贝尔曼方程</h2>


<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726236383612-d803bbb4-c840-4ddf-8c93-7357f06da0a3.png"></p>
<p>上一节中提到了动作价值函数，那么如何计算，这就需要用到<font style="background-color:#FBDE28;">贝尔曼方程</font>，即$ Q(s,a)&#x3D;R(s)+\gamma \max_{a’}Q(s’,a’) $。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726236581187-25cea284-f4f7-48d0-be8a-b5cc1c723385.png"></p>
<p>之前我们一直计算的都是最优的情况，但是实际上即使我们做出了最优的决策，但是仍存在可能事情不按照我们的决策进行，因此我们对于未来得到的回报就需要加上一个期望，表示在各种概率下的加权平均。</p>
<p>对于具体如何计算，可以参考这篇博客，用具体的例子展示了怎么使用贝尔曼方程列出等式并求解。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/november_chopin/article/details/106589197">强化学习 1 —— 一文读懂马尔科夫决策过程（MDP）-CSDN博客</a></p>
<h2 id="aO70C">连续状态应用</h2>


<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726649653666-1d559a7e-3237-4b67-adb9-60843bebbdf3.png"></p>
<p>我们之前讲的全部都是在离散的状态下进行的计算，但是在现实中很多东西都不是离散的，因此我们可以使用一个向量将这些数据作为输入进行计算，例如控制一个直升机，我们就需要有$ x,y,z $三个轴，偏移方向，角速度等。</p>
<h2 id="MHSDP"><font style="color:rgb(0, 0, 0);">Deep Q-Network</font></h2>


<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726650010452-f655730d-7687-4781-bc16-f2226e2b601f.png"></p>
<p>我们通过将深度学习的神经网络引入强化学习中，通过计算不同的$ Q(s,a) $得到最优的那个。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726651251286-7f2cc463-ebda-4007-bbc9-47141c6c52fe.png"></p>
<p>我们将状态值和决策设置为$ x $，将计算得到的$ y $设置为标签。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726655233437-6b032134-96d7-4f52-a6c1-bc6cbbec3ded.png"></p>
<p>在这个算法中，首先随机初始化全部的$ Q(s,a) $函数，接着启动月球登陆器，收集信息，并将其存储在一个回放缓冲区中，接下来训练这个神经网络，我们得到一个新的$ Q_{new} $并使得这个数尽可能的靠近我们的计算值，最终将这个新的$ Q_{new} $设置为新的$ Q $。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726655717999-956d66b9-266b-435a-9d36-5f30ab727937.png"></p>
<p>在之前的那个网络中我们需要对于每个决策都计算一次，但是我们可以改进这个神经网络的输出层，使得这个输出层可以一次计算四个值。</p>
<h2 id="JJe8K">$ \epsilon $贪婪策略</h2>


<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726656032263-9db4bf2f-2158-4fc5-932a-4c836c32a109.png"></p>
<p>由于之前的$ Q $值都是随机初始化的，因此我们选择最大值有的时候可能会很糟糕，我们引入了一个新的策略，使用一个超参数$ \epsilon $，使得这个算法可以在探索$ （exploration） $和利用$ （exploitation） $之间进行权衡。我们有$ \epsilon $的可能性不根据最大值选择而是进行不同的尝试。</p>
<h2 id="KXJ98">小批量和软更新</h2>


<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726656450338-bd1e49c0-2408-4878-ad7b-2e0ecc72156d.png"></p>
<p>如果有很多的样本用例，可能是$ 10000000 $，如果一次更新那么在进行梯度下降运算的时候会很麻烦，因此，我们可以划分不同的$ mini-batch $，一次更新$ 32 $个，虽然这样看起来在趋于最小值的过程中显得十分曲折，但是最终也是会到达全局的最小值。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726656683775-51684b5c-19b6-40fa-b78a-98f81f829809.png"></p>
<p>同时，在我们之前的更新中我们是直接将$ Q_{new} $设置为$ Q $，因此，如果我们训练的$ Q_{new} $并不是很好的话很可能使得$ Q $变得更糟糕，因此我们可以使用软更新，也就是例如上面的$ w,b $，使得新的值占的权重仅仅是一部分而不是全部。</p>
<h2 id="VWbHt">马尔科夫推导-白板推导版</h2>

<h3 id="zGvkI">背景介绍</h3>



<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726150873590-787a3380-d63b-4f5c-aec2-07e0026fe8ff.png"></p>
<h3 id="CwBPj">动态特性</h3>


<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726204536895-3c8db483-9bc1-470d-80a9-c042e64e309f.png"></p>
<h3 id="bIxaM">价值函数</h3>


<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726223602333-e74a970c-196f-4369-bea2-33f0f3c5f980.png"></p>
<h3 id="FHJoG">贝尔曼期望方程</h3>


<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726225565356-8535e491-af85-4123-a481-340f1c957316.png"></p>
<h3 id="Y4Kgw">贝尔曼最优方程</h3>


<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1726227238694-a3ea5ec0-60eb-4912-ad22-a02ce3480e0b.png"></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>强化学习</p><p><a href="https://yzd11.github.io/2024/09/18/强化学习/">https://yzd11.github.io/2024/09/18/强化学习/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>yzd</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2024-09-18</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2024-11-19</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Reinforcement-learning/">Reinforcement learning</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2024/10/08/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">支持向量机</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/09/10/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"><span class="level-item">推荐系统</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://s2.loli.net/2024/11/11/Ryr92nIiLw3mVQB.jpg" alt="yzd"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">yzd</p><p class="is-size-6 is-block">Computer Science</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>郑州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">24</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Category</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">3</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/yzd11/" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/yzd11/"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="语雀" href="https://www.yuque.com/yzd11/myblog/"><i class="fa-solid fa-feather"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="CSDN" href="https://blog.csdn.net/yzd111/"><i class="fa-solid fa-c"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Blog" href="https://yzd11.github.io/"><i class="fa-brands fa-blogger-b"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#xu0Pq"><span class="level-left"><span class="level-item">1</span><span class="level-item">引入</span></span></a></li><li><a class="level is-mobile" href="#kl2xD"><span class="level-left"><span class="level-item">2</span><span class="level-item">策略</span></span></a></li><li><a class="level is-mobile" href="#xkWyp"><span class="level-left"><span class="level-item">3</span><span class="level-item">马尔科夫决策过程</span></span></a></li><li><a class="level is-mobile" href="#apBak"><span class="level-left"><span class="level-item">4</span><span class="level-item">贝尔曼方程</span></span></a></li><li><a class="level is-mobile" href="#aO70C"><span class="level-left"><span class="level-item">5</span><span class="level-item">连续状态应用</span></span></a></li><li><a class="level is-mobile" href="#MHSDP"><span class="level-left"><span class="level-item">6</span><span class="level-item">Deep Q-Network</span></span></a></li><li><a class="level is-mobile" href="#JJe8K"><span class="level-left"><span class="level-item">7</span><span class="level-item">$ \epsilon $贪婪策略</span></span></a></li><li><a class="level is-mobile" href="#KXJ98"><span class="level-left"><span class="level-item">8</span><span class="level-item">小批量和软更新</span></span></a></li><li><a class="level is-mobile" href="#VWbHt"><span class="level-left"><span class="level-item">9</span><span class="level-item">马尔科夫推导-白板推导版</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#zGvkI"><span class="level-left"><span class="level-item">9.1</span><span class="level-item">背景介绍</span></span></a></li><li><a class="level is-mobile" href="#CwBPj"><span class="level-left"><span class="level-item">9.2</span><span class="level-item">动态特性</span></span></a></li><li><a class="level is-mobile" href="#bIxaM"><span class="level-left"><span class="level-item">9.3</span><span class="level-item">价值函数</span></span></a></li><li><a class="level is-mobile" href="#FHJoG"><span class="level-left"><span class="level-item">9.4</span><span class="level-item">贝尔曼期望方程</span></span></a></li><li><a class="level is-mobile" href="#Y4Kgw"><span class="level-left"><span class="level-item">9.5</span><span class="level-item">贝尔曼最优方程</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/blog/"><span class="level-start"><span class="level-item">blog</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-20T10:58:21.000Z">2024-11-20</time></p><p class="title"><a href="/2024/11/20/BERT/">BERT</a></p><p class="categories"><a href="/categories/blog/">blog</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-19T08:27:32.000Z">2024-11-19</time></p><p class="title"><a href="/2024/11/19/Self-Attention/">Self-Attention</a></p><p class="categories"><a href="/categories/blog/">blog</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-08T14:27:09.000Z">2024-11-08</time></p><p class="title"><a href="/2024/11/08/Transformer/">Transformer</a></p><p class="categories"><a href="/categories/blog/">blog</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-24T13:28:27.000Z">2024-10-24</time></p><p class="title"><a href="/2024/10/24/RNN/">RNN</a></p><p class="categories"><a href="/categories/blog/">blog</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-19T14:18:19.000Z">2024-10-19</time></p><p class="title"><a href="/2024/10/19/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">训练神经网络</a></p><p class="categories"><a href="/categories/blog/">blog</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/07/"><span class="level-start"><span class="level-item">July 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-learning/"><span class="tag">Reinforcement learning</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://s2.loli.net/2024/11/11/wIobSZOAEGchgVv.png" alt="yzd&#039;s Log Book" height="28"></a><p class="is-size-7"><span>&copy; 2025 yzd</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">用💖发电</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/yzd11/"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>