<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="referrer" content="no-referrer"><title>Self-Attention - yzd&#039;s Log Book</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="yzd&#039;s Log Book"><meta name="msapplication-TileImage" content="/img/redhat.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="yzd&#039;s Log Book"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="了解 Self-Attention"><meta property="og:type" content="blog"><meta property="og:title" content="Self-Attention"><meta property="og:url" content="https://yzd.life/2024/10/21/Self-Attention/"><meta property="og:site_name" content="yzd&#039;s Log Book"><meta property="og:description" content="了解 Self-Attention"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730626794760-70760341-8574-45b9-a3c8-f053db82a286.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730626868758-ccdc176b-804b-4e0d-b5ba-3892fc9534e1.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627020310-36ff30fe-0a5a-4da6-9bf5-68c229d8a23b.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627177270-32a133c4-d835-4d7a-a71a-996b40f298cc.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627479789-d7a3b789-f0ed-42b6-b984-4da3b6cea297.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627584221-1b4f25f0-bf6d-4f64-9b1d-e1c371f9dde1.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627656315-4926de97-a7e6-450c-b6fd-da1af48c424e.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627807219-55bc4fcc-cbd3-47df-97fb-8419c6a80c60.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627886953-8355bc29-b4dd-4ca3-9d94-90cbbd5073e3.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730628003983-76b449d9-a72a-411c-ae24-d0bf1c7ff40e.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730637942593-5e6d6877-69bd-483c-90e2-fa8a87cb36fb.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638095733-c78c92d4-d283-459b-b0cb-bfd93670c149.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638446918-22e10f2d-4f17-4d33-b30a-090b26fe9eac.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638548666-78192bb2-802c-46a6-8809-bd663117294f.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638822675-ff031db3-93cf-4783-bb62-340f3d0c31c1.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638898650-584f86a7-240a-42e7-87bd-b705269243e4.png"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730639590567-3ec154cd-7f6b-4149-949f-b2a1f8749511.png"><meta property="article:published_time" content="2024-10-21T02:57:51.000Z"><meta property="article:modified_time" content="2024-11-11T05:54:11.837Z"><meta property="article:author" content="yzd"><meta property="article:tag" content="Deep Learning"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730626794760-70760341-8574-45b9-a3c8-f053db82a286.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://yzd.life/2024/10/21/Self-Attention/"},"headline":"Self-Attention","image":["https://cdn.nlark.com/yuque/0/2024/png/40370285/1730626794760-70760341-8574-45b9-a3c8-f053db82a286.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730626868758-ccdc176b-804b-4e0d-b5ba-3892fc9534e1.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627020310-36ff30fe-0a5a-4da6-9bf5-68c229d8a23b.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627177270-32a133c4-d835-4d7a-a71a-996b40f298cc.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627479789-d7a3b789-f0ed-42b6-b984-4da3b6cea297.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627584221-1b4f25f0-bf6d-4f64-9b1d-e1c371f9dde1.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627656315-4926de97-a7e6-450c-b6fd-da1af48c424e.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627807219-55bc4fcc-cbd3-47df-97fb-8419c6a80c60.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627886953-8355bc29-b4dd-4ca3-9d94-90cbbd5073e3.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730628003983-76b449d9-a72a-411c-ae24-d0bf1c7ff40e.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730637942593-5e6d6877-69bd-483c-90e2-fa8a87cb36fb.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638095733-c78c92d4-d283-459b-b0cb-bfd93670c149.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638446918-22e10f2d-4f17-4d33-b30a-090b26fe9eac.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638548666-78192bb2-802c-46a6-8809-bd663117294f.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638822675-ff031db3-93cf-4783-bb62-340f3d0c31c1.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638898650-584f86a7-240a-42e7-87bd-b705269243e4.png","https://cdn.nlark.com/yuque/0/2024/png/40370285/1730639590567-3ec154cd-7f6b-4149-949f-b2a1f8749511.png"],"datePublished":"2024-10-21T02:57:51.000Z","dateModified":"2024-11-11T05:54:11.837Z","author":{"@type":"Person","name":"yzd"},"publisher":{"@type":"Organization","name":"yzd's Log Book","logo":{"@type":"ImageObject","url":"https://yzd.life/img/redhat.svg"}},"description":"了解 Self-Attention"}</script><link rel="canonical" href="https://yzd.life/2024/10/21/Self-Attention/"><link rel="icon" href="/img/redhat.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/redhat.svg" alt="yzd&#039;s Log Book" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/yzd11/"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-21T02:57:51.000Z" title="2024/10/21 10:57:51">2024-10-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-11T05:54:11.837Z" title="2024/11/11 13:54:11">2024-11-11</time></span><span class="level-item"><a class="link-muted" href="/categories/blog/">blog</a></span><span class="level-item">10 minutes read (About 1553 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Self-Attention</h1><div class="content"><h2 id="EON2x">引入</h2>

<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730626794760-70760341-8574-45b9-a3c8-f053db82a286.png">对于一个向量的输入计算我们很容易处理，但是现在我们希望对于一个句子的多个向量进行计算，这点可以体现在文字处理上。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730626868758-ccdc176b-804b-4e0d-b5ba-3892fc9534e1.png"></p>
<p>将每个单词都作为一个向量处理，那么一个句子就是多个长度不一的向量合在一起。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627020310-36ff30fe-0a5a-4da6-9bf5-68c229d8a23b.png"></p>
<p>对于多个向量的输入对应的输出可能分为三种情况，每个向量对应一个标签，全部向量对应一个标签，模型自己选择输出几个标签，今天主要处理的是第一种，即一个向量对应一个标签。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627177270-32a133c4-d835-4d7a-a71a-996b40f298cc.png"></p>
<p>对于多个向量要想同时考虑到，可以使用一个$ window $，但是这不是最好的，因为这个窗口的大小是不固定，无法考虑到全部的向量，对于这种情况可以使用$ Self-Attention $。</p>
<h2 id="C6Q8i">Self-Attention</h2>
![](https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627369098-d43ffdd6-8146-4600-832e-f0e3e58e5959.png)

<p>我们可以多次使用$ self-attention $，然后配合上全连接网络使用，这个也被称为自注意力机制。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627479789-d7a3b789-f0ed-42b6-b984-4da3b6cea297.png"></p>
<p>我们希望计算$ b^1 $的时候可以对于$ a^1 $同时考虑到$ a^2,a^3,a^4 $，因此我们需要知道他们彼此之间的关联性。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627584221-1b4f25f0-bf6d-4f64-9b1d-e1c371f9dde1.png"></p>
<p>也就是使用一个$ \alpha $来计算其中的关联性，对于这个$ \alpha $的计算方法有很多种，这里提到了其中两种。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627656315-4926de97-a7e6-450c-b6fd-da1af48c424e.png"></p>
<p>第一种是$ Dot-product $，先通过两个矩阵的变换再进行点乘，再$ self-attention $中使用的也是这个。第二种是$ Additive $，本次并没有使用。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627807219-55bc4fcc-cbd3-47df-97fb-8419c6a80c60.png"></p>
<p>首先使用刚才的$ Dot-product $计算$ a^1 $和它本身以及其余三个的关联性。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730627886953-8355bc29-b4dd-4ca3-9d94-90cbbd5073e3.png"></p>
<p>接着可以对输出的结果进行$ soft-max $，并不是一定要使用$ soft-max $，也可以使用$ relu $之类的方式。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730628003983-76b449d9-a72a-411c-ae24-d0bf1c7ff40e.png"></p>
<p>最后使用进行变化的结果和向量$ v $相乘，最后将相乘的结果加在一起就得到了$ b^1 $。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730637942593-5e6d6877-69bd-483c-90e2-fa8a87cb36fb.png"></p>
<p>刚才介绍了怎么得到$ b^1 $的方式，现在从矩阵乘法的角度重新介绍一下，可以看到将合在一起的矩阵$ I $乘上三个不同的矩阵，就可以得到$ Q,K,V $这三个矩阵。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638095733-c78c92d4-d283-459b-b0cb-bfd93670c149.png"></p>
<p>使用得到的矩阵$ K $的转置和矩阵$ Q $相乘，就可以得到矩阵$ A $，通过$ soft-max $就可以得到$ {A’} $</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638446918-22e10f2d-4f17-4d33-b30a-090b26fe9eac.png"></p>
<p>将得到的矩阵$ {A’} $和$ V $相乘就可以得到我们的输出向量$ O $，其实刚才的操作就是矩阵的相乘。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638548666-78192bb2-802c-46a6-8809-bd663117294f.png"></p>
<p>上图中从$ I $到$ O $的改变就是做的$ self-attention $的操作，其中就只有$ W^q,W^k,W^v $这三个矩阵参数是需要我们学习的。</p>
<h2 id="r6LP6">多头自注意力机制</h2>
![](https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638668529-da28ab9b-07e1-425f-99ed-b2606da55413.png)

<p>在计算相关性的时候可能不仅只有一种相关性，因此我们可以将$ q^i,k^i,v^i $的值都再乘不同的两个矩阵，最终可以得到两个$ b^{i,1},b^{i,2} $。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638822675-ff031db3-93cf-4783-bb62-340f3d0c31c1.png"></p>
<p>最后乘上一个$ W^o $的向量，可以得到一个$ b^i $的值。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730638898650-584f86a7-240a-42e7-87bd-b705269243e4.png"></p>
<p>刚才的计算中还存在一个问题，我们没有考虑向量之间的位置关系，不同的位置的影响没有被考虑进来，为了解决这个问题，我们可以计算每个位置对应的向量，将这个向量和$ a^i $相加进行计算从而将位置的信息也考虑进来。</p>
<h2 id="O6qhl">CNN v.s. self-attention</h2>
![](https://cdn.nlark.com/yuque/0/2024/png/40370285/1730639423556-6dee23e1-22e8-4fd5-a8fe-affd10918c00.png)

<p>$ CNN $和$ self-attention $之间有很强的相关性，我们可以认为$ CNN $就是一个简化版的$ self-attention $，区别在于$ self-attention $更加的灵活，让机器自己去学习和自己相关的$ pixel $，而不是人为的设置感受野，对于$ self-attention $进行一些限制就可以做到$ CNN $一样的事。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/40370285/1730639590567-3ec154cd-7f6b-4149-949f-b2a1f8749511.png"></p>
<p>既然$ self-attention $更加的灵活，那么也就代表更加容易过拟合，因此数据量很大的时候$ self-attention $的效果是要好于$ CNN $，但数据量不足的时候$ CNN $的效果就要比$ self-attention $要好一些。</p>
<h2 id="iWksS">RNN v.s. self-attention</h2>
![](https://cdn.nlark.com/yuque/0/2024/png/40370285/1730640096581-9284fd5a-1f61-4bfa-8c3d-cd6ddd21ea4b.png)

<p>对于$ RNN $来讲，$ self-attention $虽然也都是处理多个向量的输入的，但是它并不是同时处理的，而是从左到右，在处理左边的时候无法考虑到右边，虽然也可以通过双向的$ RNN $完善，但是它也不是并行计算，因此现在更加倾向于使用$ self-attention $。</p>
<p>可参照：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43610114/article/details/126684999">Transformer：注意力机制（attention）和自注意力机制（self-attention）的学习总结_注意力机制和自注意力机制-CSDN博客</a></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Self-Attention</p><p><a href="https://yzd.life/2024/10/21/Self-Attention/">https://yzd.life/2024/10/21/Self-Attention/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>yzd</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2024-10-21</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2024-11-11</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Deep-Learning/">Deep Learning</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2024/11/11/Transformer/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Transformer</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/10/11/RNN/"><span class="level-item">RNN</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="yzd"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">yzd</p><p class="is-size-6 is-block">Artificial Intelligence Machine Learning Computer Science</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>郑州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">5</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Category</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tag</p><a href="/tags"><p class="title">1</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/yzd11/" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/yzd11/"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="语雀" href="https://www.yuque.com/yzd11/myblog/"><i class="fa-solid fa-feather"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="CSDN" href="https://blog.csdn.net/yzd111/"><i class="fa-solid fa-c"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Blog" href="https://yzd.life/"><i class="fa-brands fa-blogger-b"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#EON2x"><span class="level-left"><span class="level-item">1</span><span class="level-item">引入</span></span></a></li><li><a class="level is-mobile" href="#C6Q8i"><span class="level-left"><span class="level-item">2</span><span class="level-item">Self-Attention</span></span></a></li><li><a class="level is-mobile" href="#r6LP6"><span class="level-left"><span class="level-item">3</span><span class="level-item">多头自注意力机制</span></span></a></li><li><a class="level is-mobile" href="#O6qhl"><span class="level-left"><span class="level-item">4</span><span class="level-item">CNN v.s. self-attention</span></span></a></li><li><a class="level is-mobile" href="#iWksS"><span class="level-left"><span class="level-item">5</span><span class="level-item">RNN v.s. self-attention</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/blog/"><span class="level-start"><span class="level-item">blog</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-11T03:57:52.000Z">2024-11-11</time></p><p class="title"><a href="/2024/11/11/Transformer/">Transformer</a></p><p class="categories"><a href="/categories/blog/">blog</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-21T02:57:51.000Z">2024-10-21</time></p><p class="title"><a href="/2024/10/21/Self-Attention/">Self-Attention</a></p><p class="categories"><a href="/categories/blog/">blog</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-11T04:57:51.000Z">2024-10-11</time></p><p class="title"><a href="/2024/10/11/RNN/">RNN</a></p><p class="categories"><a href="/categories/blog/">blog</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-21T04:51:47.000Z">2024-09-21</time></p><p class="title"><a href="/2024/09/21/%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">训练神经网络</a></p><p class="categories"><a href="/categories/blog/">blog</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-17T01:57:51.000Z">2024-09-17</time></p><p class="title"><a href="/2024/09/17/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%EF%BC%9AKNN%E5%92%8C%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8/">图像分类:KNN和线性分类器</a></p><p class="categories"><a href="/categories/blog/">blog</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">5</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/redhat.svg" alt="yzd&#039;s Log Book" height="28"></a><p class="is-size-7"><span>&copy; 2024 yzd</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">用💖发电</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/yzd11/"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>